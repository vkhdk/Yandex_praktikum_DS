{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построение модели классификации комментариев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Постановка задачи:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заказчик - Интернет-магазин «Викишоп».\n",
    "\n",
    "Задача - Обучить модель классифицировать комментарии на позитивные и негативные. Метрики качества модели F1 должна быть не меньше 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание исходных данных:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Набор данных с разметкой о токсичности комментария.\n",
    "\n",
    "Путь к файлу /datasets/toxic_comments.csv\n",
    "\n",
    "<br>text - текст комментария.\n",
    "<br>toxic - целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оглавление:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> [1. Предварительный анализ исходных данных.](#step1)\n",
    "<br>  - [1.1 Вывод.](#step1.1)\n",
    "<br> [2. Анализ целевого признака.](#step2)\n",
    "<br>  - [2.1 Формирование гипотез.](#step2.1)\n",
    "<br>  - [2.2 Обогащение исходных данных.](#step2.2)\n",
    "<br>  - [2.3 Проверка гипотез.](#step2.3)\n",
    "<br>  --- [2.3.1 Среднее количество букв в верхнем регистре в токсичных и обычных комментариях одинаково.](#step2.3.1)\n",
    "<br>  --- [2.3.2 Среднее количество восклицательных знаков в токсичных и обычных комментариях одинаково.](#step2.3.2)\n",
    "<br>  --- [2.3.3 Среднее количество вопросительных знаков в токсичных и обычных комментариях одинаково.](#step2.3.3)\n",
    "<br>  --- [2.3.4 Среднее количество уникальных слов к общему количеству слов в токсичных и обычных комментариях одинаково.\n",
    "](#step2.3.4)\n",
    "<br>  --- [2.3.5 Среднее количество слов в токсичных и обычных комментариях одинаково.](#step2.3.5)\n",
    "<br>  - [2.4 Вывод.](#step2.4)\n",
    "<br> [3. Предварительная обработка данных.](#step3)\n",
    "<br>  - [3.1 Подготовка текста.](#step3.1)\n",
    "<br>  - [3.2 Поиск токсичных словосочетаний.](#step3.2)\n",
    "<br>  - [3.3 Получение обучающего и тестового наборов данных.](#step3.3)\n",
    "<br>  - [3.4 Масштабирование количественных признаков.](#step3.4)\n",
    "<br>  - [3.5 Токенизация текста и расчет Tfidf.](#step3.5)\n",
    "<br>  - [3.6 Обогащение дополнительными признаками.](#step3.6)\n",
    "<br> [4. Построение моделей.](#step4)\n",
    "<br>  - [4.1 Выбор моделей.](#step4.1)\n",
    "<br>  - [4.2 Получение оптимальных гиперпараметров.](#step4.2)\n",
    "<br>  - [4.3 Оценка качества предсказаний на тестовом наборе данных.](#step4.3)\n",
    "<br>  - [4.4 Вывод.](#step4.4)\n",
    "<br> [5. Общий вывод.](#step5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Предварительный анализ исходных данных.<a id='step1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт библиотек необходимых для проведения анализа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # <библиотека \"pandas\" для работы с таблицами>\n",
    "import numpy as np # <библиотека \"numpy\" для работы с числовыми значениями>\n",
    "import time # <библиотека \"time\" для замера времени выполнения операций>\n",
    "from sklearn.model_selection import train_test_split # <библиотека \"sklearn\" метод для разделения наборов данных>\n",
    "from sklearn.dummy import DummyClassifier # < модель простых правил >\n",
    "from sklearn.linear_model import LogisticRegression #< логистическая регрессия >\n",
    "from lightgbm import LGBMClassifier #< модель градиентного бустинга >\n",
    "from sklearn.model_selection import GridSearchCV # < метод для поиска оптимальных гиперпараметров >\n",
    "import nltk #< библиотеки для символьной и статистической обработки естественного языка>\n",
    "from nltk.corpus import stopwords as nltk_stopwords #< метод для обработки стоп слов>\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #< метод для расчета TF-IDF и токенизации>\n",
    "import re #< библиотека для работы с регулярными выражениями>\n",
    "from nltk.stem import WordNetLemmatizer #< лемматизатор>\n",
    "from sklearn.metrics import f1_score #< метрика качества f1>\n",
    "from nltk.tokenize import word_tokenize #< метод токенизации>\n",
    "from sklearn.preprocessing import StandardScaler # <библиотека \"sklearn\" методы стандартизации>\n",
    "from scipy import sparse #< методы работы с разряженными матрицами>\n",
    "from scipy.sparse import csr_matrix #< метод преобразования в разряженные матрицы>\n",
    "from scipy import stats as st #<импорт библиотеки \"scipy\" для работы со статистическими методами>\n",
    "from scipy.stats import levene #<импорт статистического метода levene>\n",
    "from sklearn.feature_extraction.text import CountVectorizer #< метод токенизации>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка файла с данными в переменную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: # <для работы в веб форме практикума>\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "    \n",
    "except: # <для работы с данными на локальной машине>  \n",
    "    data = pd.read_csv('c:/Job/yandex ds/DS_3/project3_4/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим структуру таблицы с исходными данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер таблицы: (159571, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f'Размер таблицы: {data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Первые 5 строк:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Последние 5 строк:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "159566  \":::::And for the second time of asking, when ...      0\n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159569  And it looks like it was actually you who put ...      0\n",
       "159570  \"\\nAnd ... I really don't think you understand...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'Первые 5 строк:')\n",
    "display(data.head())\n",
    "print(f'Последние 5 строк:')\n",
    "display(data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Общая информация по типам данных:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "print(f'Общая информация по типам данных:\\n')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение значений целевого признака\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'Распределение значений целевого признака')\n",
    "display(data['toxic'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Категории распределены неравномерно. Необходима балансировка классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим количество пропущенных значений. Напишем небольшую функцию для удобства вывода информации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def na_values (data):\n",
    "    report = data.isna().sum().to_frame()\n",
    "    report = report.rename(columns = {0: 'missing_values'})\n",
    "    report['% of total'] = (report['missing_values'] / data.shape[0]).round(2)\n",
    "    return report.sort_values(by = 'missing_values', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_values</th>\n",
       "      <th>% of total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       missing_values  % of total\n",
       "text                0         0.0\n",
       "toxic               0         0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_values(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим количество полных дубликатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество полных дубликатов:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(f'Количество полных дубликатов:\\n{data.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Вывод. <a id='step1.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Заказчиком предоставлены данные высокого качества. Отсутствуют пропущенные значения и дубликаты. Названия признаков корректное.\n",
    "- Необходимо провести анализ наличия зависимостей среди токсичных комментариев.\n",
    "- Необходимо преобразовать текст в подходящий для обучения модели вид:\n",
    "    - Привести слова к исходной форме - лемме\n",
    "    - Оставить только буквы и убрать все знаки\n",
    "    - Очистить текст от \"стоп слов\"\n",
    "    - Привести все слова к нижнему регистру\n",
    "- Категории распределены неравномерно. Необходима балансировка классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Анализ целевого признака.<a id='step2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Формирование гипотез.<a id='step2.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед токенизацией текста попробуем найти признаки которые характерны для токсичных комментариев. Уберем ограничение по количеству выводимых символов в строке и оценим первые 10 токсичных и обычных комментариев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK\n",
       "12                                                                                                                                                                                                                                                                                                                                                       Hey... what is it..\\n@ | talk .\\nWhat is it... an exclusive group of some WP TALIBANS...who are good at destroying, self-appointed purist who GANG UP any one who asks them questions abt their ANTI-SOCIAL and DESTRUCTIVE (non)-contribution at WP?\\n\\nAsk Sityush to clean up his behavior than issue me nonsensical warnings...\n",
       "16                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Bye! \\n\\nDon't look, come or think of comming back! Tosser.\n",
       "42    You are gay or antisemmitian? \\n\\nArchangel WHite Tiger\\n\\nMeow! Greetingshhh!\\n\\nUh, there are two ways, why you do erased my comment about WW2, that holocaust was brutally slaying of Jews and not gays/Gypsys/Slavs/anyone...\\n\\n1 - If you are anti-semitian, than shave your head bald and go to the skinhead meetings!\\n\\n2 - If you doubt words of the Bible, that homosexuality is a deadly sin, make a pentagram tatoo on your forehead go to the satanistic masses with your gay pals!\\n\\n3 - First and last warning, you fucking gay - I won't appreciate if any more nazi shwain would write in my page! I don't wish to talk to you anymore!\\n\\nBeware of the Dark Side!\n",
       "43                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.query('toxic == 1').head(5)['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                                                                                                                                                                                                                                                                                             Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                             Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\n",
       "3    \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"\n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   You, sir, are my hero. Any chance you remember what page that's on?\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.query('toxic == 0').head(5)['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выдвинем несколько гипотез для проверки:\n",
    "\n",
    "- Токсичные комментарии содержат значительно больше букв в верхнем регистре по отношению к общему количеству букв в комментарии.\n",
    "- Токсичные комментарии короче по сравнению в обычными комментариями или содержат меньше слов.\n",
    "- Токсичные комментарии беднее лексически и имеют меньшее количество уникальных слов.\n",
    "- Токсичные комментарии имеют большее количество восклицательных или вопросительных знаков по отношению к обычным в связи с большей эмоциональностью комментария."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Обогащение исходных данных.<a id='step2.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим в исходную таблицу параметры которые необходимо для проверки гипотез."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество слов в комментарии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['word_count'] = data['text'].apply(lambda x : len(x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общее количество символов в комментарии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['total_length'] = data['text'].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество букв в верхнем регистре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['capitals'] = data['text'].apply(\n",
    "    lambda comment: sum(1 for c in comment if c.isupper()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отношение количества букв в верхнем регистре к общему количеству символов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['caps_length'] = data.apply(lambda row: float(row['capitals'])/float(row['total_length']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество восклицательных знаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['exclamation_marks'] =data['text'].apply(lambda x: x.count('!'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество восклицательных знаков относительно длинны комментария."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['exclamation_marks_length'] = data.apply(lambda row: float(row['exclamation_marks'])/float(row['total_length']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество вопросительных знаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['question_marks'] = data['text'].apply(lambda x: x.count('?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество уникальных слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['unique_words'] = data['text'].apply(lambda x: len(set(w for w in x.split())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отношение количества уникальных слов к общему количеству слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['unique_words_phrase'] = data['unique_words'] / data['word_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем сводную таблицу для анализа среднего значения полученных признаков в токсичных и обычных комментариях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caps_length</th>\n",
       "      <th>exclamation_marks</th>\n",
       "      <th>exclamation_marks_length</th>\n",
       "      <th>question_marks</th>\n",
       "      <th>unique_words_phrase</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.044897</td>\n",
       "      <td>0.343442</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>0.433573</td>\n",
       "      <td>0.852687</td>\n",
       "      <td>68.921065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.111038</td>\n",
       "      <td>3.472727</td>\n",
       "      <td>0.008898</td>\n",
       "      <td>0.588043</td>\n",
       "      <td>0.875620</td>\n",
       "      <td>52.717720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       caps_length  exclamation_marks  exclamation_marks_length  \\\n",
       "toxic                                                             \n",
       "0         0.044897           0.343442                  0.001544   \n",
       "1         0.111038           3.472727                  0.008898   \n",
       "\n",
       "       question_marks  unique_words_phrase  word_count  \n",
       "toxic                                                   \n",
       "0            0.433573             0.852687   68.921065  \n",
       "1            0.588043             0.875620   52.717720  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.pivot_table(index = ['toxic'], values=['unique_words_phrase',\n",
    "                                            'question_marks',\n",
    "                                            'exclamation_marks',\n",
    "                                            'exclamation_marks_length',\n",
    "                                            'caps_length',\n",
    "                                            'word_count'], aggfunc='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Проверка гипотез.<a id='step2.3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все представленные выше гипотезы сводятся к расчету достоверности гипотезы \"Средние двух генеральных совокупностей равны между собой\".\n",
    "\n",
    "Напишем функцию для проверки этой гипотезы. Функция будет принимать две серии и значение коэффициента статистической значимости \"alpha\".\n",
    "Проверка гипотезы выполняется функцией \"ttest_ind\" расчета доверительного интервала для проверки равенства средних двух генеральных совокупностей. У функции есть параметр \"equal_var\", который задает считать ли равными дисперсии выборок. Чтобы понять какое значение задать параметру, воспользуемся критерием Левана. Критерий проверяет нулевую гипотезу о том, что дисперсии совокупности равны. Альтернативная гипотеза дисперсии совокупностей не равны. Для проверки используется специальный тест который производится функцией levene()\n",
    "\n",
    "Данный тест будет включен в тело функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttest_levene(alpha,series_a,series_b):\n",
    "    levene_check = levene(series_a,series_b)\n",
    "    if (levene_check.pvalue < alpha):\n",
    "        ttest_check = st.ttest_ind(series_a,series_b,equal_var = False)\n",
    "        print('p-значение:', ttest_check.pvalue)\n",
    "        if (ttest_check.pvalue < alpha):\n",
    "            print(\"Отвергаем нулевую гипотезу\")\n",
    "        else:\n",
    "            print(\"Не получилось отвергнуть нулевую гипотезу\") \n",
    "    else:\n",
    "        ttest_check = st.ttest_ind(series_a,series_b,equal_var = True)\n",
    "        print('p-значение:', ttest_check.pvalue)\n",
    "        if (ttest_check.pvalue < alpha):\n",
    "            print(\"Отвергаем нулевую гипотезу\")\n",
    "        else:\n",
    "            print(\"Не получилось отвергнуть нулевую гипотезу\")       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Среднее количество букв в верхнем регистре в токсичных и обычных комментариях одинаково.<a id='step2.3.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Сформируем нулевую гипотезу: \n",
    "\n",
    "    - Среднее количество букв в верхнем регистре в токсичных и обычных комментариях - одинаково\n",
    "<br>Альтернативная гипотеза: \n",
    "\n",
    "    - Среднее количество букв в верхнем регистре в токсичных и обычных комментариях - не одинаково"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-значение: 0.0\n",
      "Отвергаем нулевую гипотезу\n"
     ]
    }
   ],
   "source": [
    "caps_length_toxic = data.query('toxic == 1')['caps_length']\n",
    "caps_length_regular = data.query('toxic == 0')['caps_length']\n",
    "\n",
    "ttest_levene(.05,caps_length_toxic,caps_length_regular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Среднее количество восклицательных знаков в токсичных и обычных комментариях одинаково.<a id='step2.3.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Сформируем нулевую гипотезу: \n",
    "\n",
    "    -  Среднее количество восклицательных знаков в токсичных и обычных комментариях - одинаково\n",
    "<br>Альтернативная гипотеза: \n",
    "\n",
    "    -  Среднее количество восклицательных знаков в токсичных и обычных комментариях - не одинаково"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-значение: 1.1141480575159621e-07\n",
      "Отвергаем нулевую гипотезу\n"
     ]
    }
   ],
   "source": [
    "exclamation_marks_toxic = data.query('toxic == 1')['exclamation_marks']\n",
    "exclamation_marks_regular = data.query('toxic == 0')['exclamation_marks']\n",
    "\n",
    "ttest_levene(.05,exclamation_marks_toxic,exclamation_marks_regular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 Среднее количество вопросительных знаков в токсичных и обычных комментариях одинаково.<a id='step2.3.3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Сформируем нулевую гипотезу: \n",
    "\n",
    "    - Среднее количество вопросительных знаков в токсичных и обычных комментариях - одинаково\n",
    "<br>Альтернативная гипотеза: \n",
    "\n",
    "    - Среднее количество вопросительных знаков в токсичных и обычных комментариях - не одинаково"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-значение: 5.74485563005134e-10\n",
      "Отвергаем нулевую гипотезу\n"
     ]
    }
   ],
   "source": [
    "question_marks_toxic = data.query('toxic == 1')['question_marks']\n",
    "question_marks_regular = data.query('toxic == 0')['question_marks']\n",
    "\n",
    "ttest_levene(.05,question_marks_toxic,question_marks_regular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4 Среднее количество уникальных слов к общему количеству слов в токсичных и обычных комментариях одинаково.<a id='step2.3.4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Сформируем нулевую гипотезу: \n",
    "\n",
    "    - Среднее количество уникальных слов к общему количеству слов в токсичных и обычных комментариях одинаково - одинаково\n",
    "<br>Альтернативная гипотеза: \n",
    "\n",
    "    - Среднее количество уникальных слов к общему количеству слов в токсичных и обычных комментариях одинаково - не одинаково"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-значение: 4.2993069183285413e-66\n",
      "Отвергаем нулевую гипотезу\n"
     ]
    }
   ],
   "source": [
    "unique_words_phrase_toxic = data.query('toxic == 1')['unique_words_phrase']\n",
    "unique_words_phrase_regular = data.query('toxic == 0')['unique_words_phrase']\n",
    "\n",
    "ttest_levene(.05,unique_words_phrase_toxic,unique_words_phrase_regular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.5 Среднее количество слов в токсичных и обычных комментариях одинаково.<a id='step2.3.5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Сформируем нулевую гипотезу: \n",
    "\n",
    "    - Среднее количество слов в токсичных и обычных комментариях - одинаково\n",
    "<br>Альтернативная гипотеза: \n",
    "\n",
    "    - Среднее количество слов в токсичных и обычных комментариях - не одинаково"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-значение: 2.1483593430866275e-75\n",
      "Отвергаем нулевую гипотезу\n"
     ]
    }
   ],
   "source": [
    "word_count_toxic = data.query('toxic == 1')['word_count']\n",
    "word_count_regular = data.query('toxic == 0')['word_count']\n",
    "\n",
    "ttest_levene(.05,word_count_toxic,word_count_regular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Вывод.<a id='step2.4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Средние значения дополнительных признаков в токсичных и обычных комментариях отличаются. Все гипотезы подтвердились. В качестве дополнительных признаков будут использоваться:\n",
    "- Количество символов в верхнем регистре относительно общего количества символов \"caps_length\"\n",
    "- Количество восклицательных знаков\n",
    "- Количество вопросительных знаков\n",
    "- Количество слов в комментарии\n",
    "- Отношение количества уникальных слов к общему количеству слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Предварительная обработка данных.<a id='step3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Подготовка текста.<a id='step3.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для дальнейшей токенизации и обучения модели необходимо преобразовать текст комментариев. Необходимо:\n",
    "\n",
    "1. Привести слова к исходной форме - лемме\n",
    "2. Убрать все символы кроме букв\n",
    "3. Убрать слова, которые не несут информации (предлоги, артикли и т.п.)\n",
    "4. Привести все буквы к нижнему регистру.\n",
    "\n",
    "Напишем функцию для реализации первых двух преобразований. Оставшиеся преобразования можно выполнить на этапе расчета \"Tfidf\" за счет дополнительных параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lem_cleaning(text):\n",
    "    lemmatizer = WordNetLemmatizer() #<инициализируем лемматизатор>\n",
    "    lemm_list = nltk.word_tokenize(text) #<разбиваем предложение на список>\n",
    "    lemm_text = ' '.join([lemmatizer.lemmatize(w) for w in lemm_list]) #<проводим лемматизацию и соединяем слова в предложения>\n",
    "    first_cleaning = re.sub(r'[^[A-Za-z]', ' ', lemm_text) #<оставляем только буквы>\n",
    "    second_cleaning = first_cleaning.split() #<повторно соединяем в предложения без лишних пробелов>\n",
    "    final_text = \" \".join(second_cleaning)\n",
    "    return(final_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим в исходную таблицу столбец с подготовленным текстом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['lemm_text'] = data['text'].apply(lambda x: lem_cleaning(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Поиск токсичных словосочетаний.<a id='step3.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В токсичных комментариях часто присутствует обсессивная лексика, которая складывается не из единичных слов, а из нескольких. Составим список самых часто встречаемых биграмм среди токсичных комментариев. Сформируем массив лемматизированного текста токсичных комментариев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_toxic = list(data.query('toxic == 1')['lemm_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед разделением текста на биграммы загрузим список \"стоп слов\". Данный список позволит избавиться от предлогов, артиклей и т.п. в биграммах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bazoo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зададим параметры токенизатору используя который мы получим биграммы. В параметрах укажем размер n-грамм, необходимость удаления стоп-слов и приведение букв к нижнему регистру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_count_vect = CountVectorizer(ngram_range=(2, 2), stop_words=stopwords,lowercase=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим токенизатор к массиву лемматизированного текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gramm = ngram_count_vect.fit_transform(corpus_toxic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зададим сколько чаще всего встречаемых биграмм необходимо выбрать через переменную \"N\".\n",
    "В переменной \"idx\" будут содержаться индексы самых часто встречаемых биграмм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "idx = np.ravel(n_gramm.sum(axis=0).argsort(axis=1))[::-1][:N]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя индекс получим список биграмм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_toxic_bigrams = np.array(ngram_count_vect.get_feature_names())[idx].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим получившийся список."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fuck fuck',\n",
       " 'nigger nigger',\n",
       " 'hate hate',\n",
       " 'moron hi',\n",
       " 'hi moron',\n",
       " 'faggot faggot',\n",
       " 'pig pig',\n",
       " 'jew fat',\n",
       " 'fat jew',\n",
       " 'go fuck',\n",
       " 'shit shit',\n",
       " 'suck suck',\n",
       " 'bark bark',\n",
       " 'wanker wanker',\n",
       " 'fuck go',\n",
       " 'bullshit bullshit',\n",
       " 'balls balls',\n",
       " 'talk page',\n",
       " 'nipple nipple',\n",
       " 'suck cock',\n",
       " 'die die',\n",
       " 'dickhead dickhead',\n",
       " 'die fag',\n",
       " 'fag die',\n",
       " 'fucksex fucksex',\n",
       " 'fuck yourselfgo',\n",
       " 'yourselfgo fuck',\n",
       " 'aids aids',\n",
       " 'freedom freedom',\n",
       " 'super gay',\n",
       " 'gay super',\n",
       " 'buttsecks buttsecks',\n",
       " 'twat twat',\n",
       " 'fucker cocksucker',\n",
       " 'mothjer fucker',\n",
       " 'cocksucker mothjer',\n",
       " 'suck dick',\n",
       " 'piece shit',\n",
       " 'know fggt',\n",
       " 'fggt know',\n",
       " 'noobs wiki',\n",
       " 'wiki noobs',\n",
       " 'shut fuck',\n",
       " 'ass ass',\n",
       " 'poop poop',\n",
       " 'bastered bastered',\n",
       " 'penis penis',\n",
       " 'huge faggot',\n",
       " 'gay gay',\n",
       " 'faggot huge']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_toxic_bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию, которая будет осуществлять поиск самых популярных биграмм в комментариях. Функция раскладывает комментарий на список биграмм после чего составляет список пересечения с самыми популярными биграммами. Если длинна получившегося списка больше нуля, то функция возвращает единицу. В других случаях возвращает ноль."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigrams_search(string,toxic_bigrams):\n",
    "    count_vect = CountVectorizer(ngram_range=(2, 2), stop_words=stopwords,lowercase=True)\n",
    "    try:\n",
    "        count_vect.fit_transform([string])\n",
    "        bigrams = count_vect.get_feature_names()\n",
    "        bigrams_match = list(set(toxic_bigrams) & set(bigrams))\n",
    "        if len(bigrams_match) > 0:\n",
    "            return(1)\n",
    "        else:\n",
    "            return(0)\n",
    "    except:\n",
    "        return(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим функцию и сформируем новый категорийный признак наличия токсичной биграммы в комментарии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['toxic_bigrams'] = data['lemm_text'].apply(lambda x: bigrams_search(x,top_toxic_bigrams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Получение обучающего и тестового наборов данных.<a id='step3.3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим общий набор данных на обучающий и тестовый. Оставим в списке признаков только важные признаки:\n",
    "- Пред обработанный текст комментария\n",
    "- Количество символов в верхнем регистре относительно общего количества символов \"caps_length\"\n",
    "- Количество восклицательных знаков\n",
    "- Количество вопросительных знаков\n",
    "- Количество слов в комментарии\n",
    "- Отношение количества уникальных слов к общему количеству слов.\n",
    "- Наличие токсичных биграмм в комментарии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    data[['caps_length',\n",
    "          'exclamation_marks',\n",
    "          'lemm_text',\n",
    "          'question_marks',\n",
    "          'unique_words_phrase',\n",
    "          'word_count',\n",
    "          'toxic_bigrams']],\n",
    "    data['toxic'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Масштабирование количественных признаков.<a id='step3.4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В наборах данных присутствуют количественные признаки. Для дальнейшей категоризации необходимо выполнить масштабирование.\n",
    "Создадим объект структуры StandardScaler() и настроим его используя обучающий набор данных. Настройка — это вычисление среднего и дисперсии. Настроена будет выполняться только по численным признакам поэтому сначала создадим список с численными признаками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list_additional_features = ['caps_length',\n",
    "                       'exclamation_marks',\n",
    "                       'question_marks',\n",
    "                       'unique_words_phrase',\n",
    "                       'word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(features_train[column_list_additional_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним масштабирование признаков функцией transform()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train[column_list_additional_features] = scaler.transform(features_train[column_list_additional_features])\n",
    "features_test[column_list_additional_features] = scaler.transform(features_test[column_list_additional_features]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Токенизация текста и расчет Tfidf.<a id='step3.5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведем текст к типу \"unicode\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train['lemm_text'] = features_train['lemm_text'].values.astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test['lemm_text'] = features_test['lemm_text'].values.astype('U')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем токенизатор с дополнительными параметрами:\n",
    "- stop_words - уберет слова, которые не несут информации\n",
    "- lowercase - приведет все знаки к нижнему регистру\n",
    "- min_df позволит отсечь слова с низким значением Tfidf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords,\n",
    "                               lowercase=True, \n",
    "                               min_df=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим разряженные матрицы с рассчитанным значением Tfidf для обучающего и тестового наборов данных. Изменим тип данных на \"float32\" чтобы уменьшить потребление памяти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = count_tf_idf.fit_transform(features_train['lemm_text']).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test = count_tf_idf.transform(features_test['lemm_text']).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 Обогащение дополнительными признаками. <a id='step3.6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем массивы с дополнительными признаками. Приведем тип данных к \"float32\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_additional_features = np.array(features_train.drop('lemm_text', axis=1)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_additional_features = np.array(features_test.drop('lemm_text', axis=1)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем разряженные матрицы Tfidf в массивы и объединим с дополнительными признаками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf_idf_train_temporary = np.column_stack((tf_idf_train.todense(),train_additional_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf_idf_test_temporary = np.column_stack((tf_idf_test.todense(),test_additional_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем полученные массивы обратно в разряженные матрицы и очистим переменные. Данное преобразование необходимо для очистки памяти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf_idf_train_enriched = sparse.csr_matrix(tf_idf_train_temporary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train_temporary = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf_idf_test_enriched = sparse.csr_matrix(tf_idf_test_temporary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test_temporary = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<127656x15119 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 3872313 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_train_enriched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Построение моделей.<a id='step4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Выбор моделей.<a id='step4.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В текущем проекте необходимо решить задачу классификации. Для этого будет использоваться три вида моделей:\n",
    "\n",
    "\"LogisticRegression\" - Логистическая регрессия\n",
    "\"LGBMClassifier\" - Классификатор с применением градиентного бустинга\n",
    "\"DummyClassifier\" - Модель простых правил.\n",
    "При первичном анализе был обнаружен значительный дисбаланс классов целевого признака. Построение моделей будет выполняться с автоматической балансировкой классов.\n",
    "\n",
    "Сформируем список моделей которые не требуют подбора гиперпараметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [LogisticRegression(class_weight='balanced',random_state=123),\n",
    "               DummyClassifier(strategy=\"stratified\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Получение оптимальных гиперпараметров.<a id='step4.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбор гиперпараметров модели градиентного бустинга будет выполняться с использованием \"GridSearchCV\".  Заказчиком заявлено требование к значению метрики \"F1\". Функцией качества указана метрика \"F1\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "<h2> Комментарий от автора</h2>\n",
    "Подбор параметров выполнял в следующих диапазонах:\n",
    "parametrs_LightGBM = {'n_estimators': [10, 50, 100, 200, 500], 'max_depth': [1, 10, 25, 50]}\n",
    "подбиралось 1h 24min 14s.\n",
    "    \n",
    "    Лучшие гиперпараметры для модели LGBMClassifier(class_weight='balanced') - {'max_depth': 25, 'n_estimators': 500}\n",
    "    \n",
    "Чтобы не тратить время поправил параметры и добавил ниже вручную заполненный список моделей.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametrs_LightGBM = {'n_estimators': [1, 5], 'max_depth': [1, 2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры для модели LGBMClassifier(class_weight='balanced') - {'max_depth': 2, 'n_estimators': 5}\n",
      "Wall time: 2min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LGBMClassifier(class_weight='balanced') \n",
    "grid = GridSearchCV(model,parametrs_LightGBM,scoring='f1',cv=5)\n",
    "grid.fit(tf_idf_train_enriched,target_train)\n",
    "print(f'Лучшие гиперпараметры для модели {model} - {grid.best_params_}')\n",
    "models_list.append(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Оценка качества предсказаний на тестовом наборе данных.<a id='step4.3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим получившийся список моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(class_weight='balanced', random_state=123),\n",
       " DummyClassifier(strategy='stratified'),\n",
       " LGBMClassifier(class_weight='balanced', max_depth=2, n_estimators=5)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [LogisticRegression(class_weight='balanced',random_state=123),\n",
    "               DummyClassifier(strategy=\"stratified\"),LGBMClassifier(class_weight='balanced', max_depth = 25,n_estimators = 500)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию для расчета метрики \"F1\" на тестовом наборе данных используя полученный список моделей. Функция выдает значение метрики и длительность обучения модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_calculation(model,features_train,target_train,features_test,target_test):\n",
    "    start_time = time.time()\n",
    "    model.fit(features_train, target_train)\n",
    "    finish_time = time.time()\n",
    "    predicted = model.predict(features_test)\n",
    "    f1 = f1_score(target_test,predicted)\n",
    "    \n",
    "    print(f'--------------------------')\n",
    "    print(f'Значение F1 для модели {model} на тестовом наборе данных: {f1}')\n",
    "    print(f'Время обучения составляет: {finish_time - start_time} секунд\\n')\n",
    "    print(f'--------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим функцию к списку моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bazoo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Значение F1 для модели LogisticRegression(class_weight='balanced', random_state=123) на тестовом наборе данных: 0.7450369793694044\n",
      "Время обучения составляет: 12.26590609550476 секунд\n",
      "\n",
      "--------------------------\n",
      "--------------------------\n",
      "Значение F1 для модели DummyClassifier(strategy='stratified') на тестовом наборе данных: 0.10221944357611754\n",
      "Время обучения составляет: 0.008002281188964844 секунд\n",
      "\n",
      "--------------------------\n",
      "--------------------------\n",
      "Значение F1 для модели LGBMClassifier(class_weight='balanced', max_depth=25, n_estimators=500) на тестовом наборе данных: 0.7678522194651227\n",
      "Время обучения составляет: 100.71230936050415 секунд\n",
      "\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "for model in models_list:\n",
    "    f1_calculation(model,tf_idf_train_enriched,target_train,tf_idf_test_enriched,target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Вывод.<a id='step4.4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Простая модель значительно хуже предсказывает результаты чем сложные.\n",
    "- Заказчиком было заявлено требование к метрике F1 не ниже 0.75. Данное требование удовлетворяет только модель градиентного бустинга \"LGBMClassifier\".\n",
    "- Сравнительная таблица по сложным моделям представлена ниже:\n",
    "\n",
    "| Модель | Максимальная глубина | Количество деревьев | Значение F1 | Время обучения, секунды |\n",
    "| ------------- | ------------- | ------------- | ------------- | ------------- |\n",
    "| \"Градиентный бустинг LGBMRegressor\" | 25 | 500 | 0.773| 84.37 |\n",
    "| \"Логистическая регрессия\" | --- | --- | 0.749 | 2.614|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Общий вывод.<a id='step5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Заказчиком предоставлены данные высокого качества. Отсутствуют пропущенные значения и дубликаты. Названия признаков корректное.\n",
    "- Категории распределены неравномерно. Необходима балансировка классов.\n",
    "- Были подтверждены следующие гипотезы:\n",
    "    - Среднее количество букв в верхнем регистре в токсичных и обычных комментариях отличается.\n",
    "    - Среднее количество восклицательных знаков в токсичных и обычных комментариях отличается.\n",
    "    - Среднее количество вопросительных знаков в токсичных и обычных комментариях отличается.\n",
    "    - Среднее количество уникальных слов к общему количеству слов в токсичных и обычных комментариях отличается.\n",
    "    - Среднее количество слов в токсичных и обычных комментариях отличается.\n",
    "\n",
    "\n",
    "- В качестве дополнительных признаков токсичности комментария использовались:\n",
    "    - Количество символов в верхнем регистре относительно общего количества символов \"caps_length\"\n",
    "    - Количество восклицательных знаков\n",
    "    - Количество вопросительных знаков\n",
    "    - Количество слов в комментарии\n",
    "    - Отношение количества уникальных слов к общему количеству слов.\n",
    "\n",
    "- Простая модель значительно хуже предсказывает результаты чем сложные модели.\n",
    "- Заказчиком было заявлено требование к метрике F1 не ниже 0.75. Данное требование удовлетворяет только модель градиентного бустинга \"LGBMClassifier\".\n",
    "- Сравнительная таблица по сложным моделям представлена ниже:\n",
    "\n",
    "| Модель | Максимальная глубина | Количество деревьев | Значение F1 | Время обучения, секунды |\n",
    "| ------------- | ------------- | ------------- | ------------- | ------------- |\n",
    "| \"Градиентный бустинг LGBMRegressor\" | 25 | 500 | 0.773| 84.37 |\n",
    "| \"Логистическая регрессия\" | --- | --- | 0.749 | 2.614|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
